{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "from difflib import SequenceMatcher\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import string\n",
    "import json\n",
    "import ast\n",
    "import os\n",
    "import re\n",
    "\n",
    "def toJson(JsponPath, destData):\n",
    "    with open(JsponPath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(destData, f, ensure_ascii=False)\n",
    "\n",
    "def openJson(JsonPath):\n",
    "    with open(JsonPath, 'r', encoding='utf-8') as f:\n",
    "        JsonData = json.load(f)\n",
    "    return JsonData\n",
    "\n",
    "def toTxt(txtPath, destData):\n",
    "    with open(txtPath, 'w', encoding='utf-8') as f:\n",
    "        for d in destData:\n",
    "            f.write(d + \"\\n\")\n",
    "\n",
    "def openTxt(txtPath):\n",
    "    with open(txtPath, 'r', encoding='utf-8') as f:\n",
    "        data = f.read().splitlines()\n",
    "    return [i.strip() for i in data]\n",
    "\n",
    "def make_all_Naver_productData(category):\n",
    "        allSkindata = {}\n",
    "        category_path = os.path.join(r'C:\\Final_Project_Files', category)\n",
    "        \n",
    "        for skin in os.listdir(category_path):\n",
    "            skinjson = os.path.join(category_path, skin, 'product.json')\n",
    "            jsonData = openJson(skinjson)\n",
    "            \n",
    "            for data in jsonData:\n",
    "                jsonData[data]['productID'] = urlparse(jsonData[data]['productImg']).path.split(\"/\")[-1].split(\".\")[0]\n",
    "                allSkindata[data] = jsonData[data]\n",
    "\n",
    "            toJson(skinjson, jsonData)\n",
    "        \n",
    "        toJson(os.path.join(category_path, f\"Naver_{category}.json\"), allSkindata)\n",
    "        \n",
    "def Ingre_preprocessing(alldataPath):\n",
    "    allData = openJson(alldataPath)\n",
    "    isingre = {}\n",
    "    notingre = {}\n",
    "\n",
    "    for data in allData:\n",
    "        if allData[data]['allIngredient']:\n",
    "            isingre[data] = allData[data]\n",
    "        else:\n",
    "            notingre[data] = allData[data]\n",
    "    \n",
    "    for Nname in notingre:\n",
    "        notingre_name = make_justName(Nname)\n",
    "        for Iname in isingre:\n",
    "            isingre_name = make_justName(Iname)\n",
    "            if notingre_name == isingre_name:\n",
    "                allData[Nname]['allIngredient'] = isingre[Iname]['allIngredient']\n",
    "                allData[Nname]['analysisIngre'] = isingre[Iname]['analysisIngre']\n",
    "                break\n",
    "    \n",
    "    re_savefile = os.path.split(alldataPath)\n",
    "    toJson(os.path.join(re_savefile[0], f'{re_savefile[-1].split(\".\")[0]}_pre.json'), allData)\n",
    "    \n",
    "    return allData\n",
    "    \n",
    "def tempCheck(alldata):\n",
    "    cnt = 0\n",
    "    for data in alldata:\n",
    "        if not alldata[data]['allIngredient']:\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "\n",
    "def make_justName(name):\n",
    "    name_split = name.split(\" \")\n",
    "    for idx, word in enumerate(name_split):\n",
    "        if re.search(\"[0-9]ml|[0-9]매|[0-9]g\", word):\n",
    "            capacity = idx\n",
    "    return \" \".join(name_split[:capacity])\n",
    "\n",
    "def tempingre(alldata):\n",
    "    namesLi = list(alldata.keys())\n",
    "    shuffle(namesLi) \n",
    "    return {i:alldata[i]['allIngredient'] for i in namesLi[:10]} \n",
    "\n",
    "def one_parenthesis_check(s):\n",
    "    return True if s.find(\"(\") == -1 and s.find(\")\") != -1 else False\n",
    "\n",
    "def punc_check(s):\n",
    "    my_punc = \"[\" + \"\".join([i for i in string.punctuation if i not in ['-', '/', '(', ')', '%']]) + \"]\"\n",
    "    return re.sub(my_punc, '', s) if re.search(my_punc, s) else s\n",
    "\n",
    "def capacity_check(s):\n",
    "    ingreCap = '\\(ci|[0-9]ppm\\)|[0-9]ppb\\)|[0-9]%\\)|[0-9]mg\\)|[0-9]pom\\)|[0-9]k\\)|[0-9]ng\\)|\\([0-9]'\n",
    "    if re.search(ingreCap, s.lower().replace(\" \", \"\")):\n",
    "        idx_finded = s.find(\"(\")\n",
    "        if idx_finded != -1:\n",
    "            return s[:idx_finded].strip()\n",
    "        else:\n",
    "            return s\n",
    "    else:\n",
    "        return s\n",
    "    \n",
    "def mapping_ingre(s):\n",
    "    result = \"\"\n",
    "    if re.search(\"2-헥산|2-핵산|2 -헥산|2 -핵산|2헥산|2핵산|2 헥산|2 핵산|2-헤산|2- 헥산\", s):\n",
    "        result = '1,2-헥산다이올'\n",
    "    elif re.search(\"디소듐 EDTA|다이소듐이디티에이|디소듐이디티에이|디소듐이티에이|호듐이디티에이\", s):\n",
    "        result = '다이소듐이디티에이'\n",
    "    elif re.search(\"렌즈콩씨추출물|에스큘렌타렌즈콩씨추출물\", s):\n",
    "        result = '렌틸콩씨추출물'\n",
    "    elif re.search(\"디메칠이미다졸리디논라이스스타치|디메칠이미다졸리디논쌀전분|다이메틸이미다졸리다이논쌀전분\", s):\n",
    "        result = '다이메틸이미다졸리디논쌀전분'\n",
    "    elif re.search(\"C13-16이소파라핀|C13-16아이소파라핀\", s):\n",
    "        result = 'C13-16아이소알케인'\n",
    "    elif re.search(\"C12-14이소파라핀|C12-14아이소파라핀\", s):\n",
    "        result = 'C12-14아이소알케인'\n",
    "    elif re.search(\"C13-14이소파라핀|C13-14아이소파라핀\", s):\n",
    "        result = 'C13-14아이소알케인'\n",
    "    elif re.search(\"사카라이드롤리세이트\", s):\n",
    "        result = '사카라이드하이드롤리세이트'\n",
    "    elif re.search(\"3-부탄|3 -부탄|3부탄\", s):\n",
    "        result = '2,3-부탄다이올'\n",
    "    elif re.search(\"베타글루칸|베타-그룰칸\", s):\n",
    "        result = '베타-글루칸'\n",
    "    elif re.search(\"비타민E\", s):\n",
    "        result = '토코페롤'\n",
    "    elif re.search(\"카렌듈라꽃추출물\", s):\n",
    "        result = '포트마리골드꽃추출물'\n",
    "    elif re.search(\"플란타인씨추출물\", s):\n",
    "        result = '블론드실리엄씨추출물'\n",
    "    elif re.search(\"아벤느 온천수|아벤느온천수\", s):\n",
    "        result = '온천수'\n",
    "    elif re.search(\"감자추출물발효여과물\", s):\n",
    "        result = '효모/감자추출물발효여과물'\n",
    "    elif re.search(\"율무씨발효여과물\", s):\n",
    "        result = '효모/율무씨발효여과물'\n",
    "    else:\n",
    "        result = s\n",
    "    return result.strip()\n",
    "\n",
    "def old_to_cur(s, ingreOldData):\n",
    "    check = s.lower().replace(\" \", \"\")\n",
    "    if s in ingreOldData.keys():\n",
    "        return ingreOldData[s]\n",
    "    elif check in ingreOldData.keys():\n",
    "        return ingreOldData[check]\n",
    "    else:\n",
    "        return s\n",
    "    \n",
    "def check_cur(s, ingreNames):\n",
    "    check = s.lower().replace(\" \", \"\")\n",
    "    for name in ingreNames:\n",
    "        if name.lower().replace(\" \", \"\") == check:\n",
    "            return name\n",
    "    else:\n",
    "        return s\n",
    "    \n",
    "def del_descript(s):\n",
    "    check = re.search(\"\\( ?[ㄱ-ㅎㅏ-ㅣ가-힣]*\", s)\n",
    "    if check:\n",
    "        return s[:check.span()[0]].strip()\n",
    "    else:\n",
    "        return s\n",
    "    \n",
    "def check_mistake(s, ingreLi):\n",
    "    return sorted([[i, SequenceMatcher(None, s, i).ratio()] for i in ingreLi], key=lambda x:x[1], reverse=True)[0]\n",
    "\n",
    "def del_digit(s):\n",
    "    check = re.search('[ㄱ-ㅎㅏ-ㅣ가-힣]+ ?[0-9]+[IU%]+', s)\n",
    "    if check:\n",
    "        digit = re.search('[0-9]+', s)\n",
    "        return s[:digit.span()[0]].strip()\n",
    "    else:\n",
    "        return s\n",
    "    \n",
    "def Final_Preprocessing(category):\n",
    "    categoryFolder = os.path.join(r'C:\\Final_Project_Files', category)\n",
    "    ingreFolder = os.path.join(r'C:\\Final_Project_Files', 'dataes', 'Ingredient')\n",
    "\n",
    "    IngreDictpath = os.path.join(ingreFolder, 'Final_Ingredient_Dictionary.json')\n",
    "    ingreOldpath = os.path.join(ingreFolder, 'temp_old.json')\n",
    "\n",
    "    IngreDict = openJson(IngreDictpath)\n",
    "    ingreOldData = openJson(ingreOldpath)\n",
    "\n",
    "    ingreNames = [i['ingreName'] for i in IngreDict]\n",
    "    ingreOldName = list(ingreOldData.keys())\n",
    "    scoreDict = {i['ingreName'] : i for i in IngreDict}\n",
    "\n",
    "    for product in tqdm(os.listdir(categoryFolder)):\n",
    "        \n",
    "        productPath = os.path.join(categoryFolder, product, 'product.json')\n",
    "        \n",
    "        if os.path.exists(productPath):\n",
    "            \n",
    "            productData = openJson(productPath)\n",
    "            productName = list(productData.keys())[0]\n",
    "\n",
    "            tempDict = {}\n",
    "            tempLi = []\n",
    "            ewgLi, dryLi, oilLi, sensitiveLi, allergyLi = [], [], [], [], []\n",
    "            \n",
    "            if productData[productName]['allIngredient']:\n",
    "                for ingre in productData[productName]['allIngredient'][:]:\n",
    "                    if not ingre.isdigit() and not one_parenthesis_check(ingre):\n",
    "                        ingre = capacity_check(punc_check(ingre))\n",
    "                        ingre = mapping_ingre(ingre)\n",
    "                        ingre = del_descript(ingre)\n",
    "                        ingre = del_digit(ingre)\n",
    "                        ingre = old_to_cur(check_cur(ingre, ingreNames), ingreOldData)\n",
    "                        tempLi.append(ingre)\n",
    "                tempDict[productName] = tempLi\n",
    "\n",
    "                for idx, ingre in enumerate(tempDict[productName][:]):\n",
    "                    if ingre not in ingreNames:\n",
    "                        cur = check_mistake(ingre, ingreNames)\n",
    "                        old = check_mistake(ingre, ingreOldName)\n",
    "                        if cur[1] >= 0.9 or old[1] >= 0.9:\n",
    "                            if cur[1] >= old[1]:\n",
    "                                tempDict[productName][idx] = cur[0]\n",
    "                            else:\n",
    "                                tempDict[productName][idx] = ingreOldData[old[0]]\n",
    "                                \n",
    "                for ingre in tempDict[productName]:\n",
    "                    if ingre in scoreDict.keys():\n",
    "                        if scoreDict[ingre]['ewgScore'] != '등급없음':\n",
    "                            ewgLi.append(scoreDict[ingre]['ewgScore'])\n",
    "                        else:\n",
    "                            ewgLi.append(\"0\")\n",
    "                        \n",
    "                        dryLi.append(str(scoreDict[ingre]['dryScore']))\n",
    "                        oilLi.append(str(scoreDict[ingre]['oilScore']))\n",
    "                        sensitiveLi.append(str(scoreDict[ingre]['sensitiveScore']))\n",
    "                        allergyLi.append(str(scoreDict[ingre]['allergyScore']))\n",
    "                    else:\n",
    "                        ewgLi.append(\"0\")\n",
    "                        dryLi.append(\"0\")\n",
    "                        oilLi.append(\"0\")\n",
    "                        sensitiveLi.append(\"0\")\n",
    "                        allergyLi.append(\"0\")\n",
    "                    \n",
    "                productData[productName]['allIngredient'] = tempDict[productName]\n",
    "                productData[productName]['productEwgScore'] = \",\".join(ewgLi)\n",
    "                productData[productName]['productDryScore'] = \",\".join(dryLi)\n",
    "                productData[productName]['productOilScore'] = \",\".join(oilLi)\n",
    "                productData[productName]['productSensitiveScore'] = \",\".join(sensitiveLi)\n",
    "                productData[productName]['productAllegyScore'] = \",\".join(allergyLi)\n",
    "                productData[productName]['Final'] = \"yes\"\n",
    "            else:\n",
    "                productData[productName]['allIngredient'] = []\n",
    "                productData[productName]['productEwgScore'] = \"0\"\n",
    "                productData[productName]['productDryScore'] = \"0\"\n",
    "                productData[productName]['productOilScore'] = \"0\"\n",
    "                productData[productName]['productSensitiveScore'] = \"0\"\n",
    "                productData[productName]['productAllegyScore'] = \"0\"\n",
    "                productData[productName]['Final'] = \"yes\"\n",
    "                \n",
    "            toJson(productPath, productData)\n",
    "                \n",
    "    print(\"Final Preprocessing Done!!\")\n",
    "\n",
    "def Glowpic_ingre_plus():\n",
    "    projectPath = os.path.join(r'C:\\Final_Project_Files', 'dataes')\n",
    "\n",
    "    ingreDict = openJson(os.path.join(projectPath, 'Final_Ingredient_Dictionary.json'))\n",
    "    glowIngre = pd.read_csv(os.path.join(projectPath, 'final_2.csv'), encoding='euc-kr')\n",
    "    ingreOld = openJson(os.path.join(projectPath, 'temp_old.json'))\n",
    "    lastproduct = openJson(os.path.join(projectPath, 'Last_Cosmetic_product.json'))\n",
    "\n",
    "    curNames = [i['ingreName'] for i in ingreDict]\n",
    "    glowIngreDict = {val['원래이름'] : {\"allIngredient\" : ast.literal_eval(val['성분']), \"ewgGrade\" : ast.literal_eval(val['등급'])} for idx, val in glowIngre.iterrows()}\n",
    "\n",
    "    for data in glowIngreDict:\n",
    "        for idx, ingre in enumerate(glowIngreDict[data]['allIngredient'][:]):\n",
    "            glowIngreDict[data]['allIngredient'][idx] = mapping_ingre(ingre)\n",
    "            if ingre.lower() in ingreOld.keys():\n",
    "                glowIngreDict[data]['allIngredient'][idx] = ingreOld[ingre.lower()]\n",
    "\n",
    "    for data in glowIngreDict:\n",
    "        lastproduct[data]['allIngredient'] = glowIngreDict[data]['allIngredient']\n",
    "        \n",
    "    toJson(os.path.join(projectPath, \"Final_Cosmetic_product.json\"), lastproduct)\n",
    "    \n",
    "def make_Final_productData(category):\n",
    "    FinalFolder = r'C:\\Final_Project_Files'\n",
    "    FinalDataFolder = os.path.join(FinalFolder, 'dataes', 'Cosmetic', 'Final')\n",
    "    \n",
    "    allCosdata = {}\n",
    "    tempCheckdata = {}\n",
    "    category_path = os.path.join(FinalFolder, category)\n",
    "    result_path = os.path.join(FinalDataFolder, f\"Final_{category}.json\")\n",
    "    \n",
    "    for cos in tqdm(os.listdir(category_path)):\n",
    "        cospath = os.path.join(category_path, cos, 'product.json')\n",
    "        if os.path.exists(cospath):    \n",
    "            jsonData = openJson(cospath)\n",
    "            allCosdata.update(jsonData)\n",
    "            for data in jsonData:\n",
    "                if jsonData[data]['allIngredient']:\n",
    "                    tempCheckdata[make_justName(data)] = jsonData[data]['allIngredient']\n",
    "    \n",
    "    for cos in allCosdata:\n",
    "        if not allCosdata[cos]['allIngredient']:\n",
    "            temp = make_justName(cos)\n",
    "            if temp in tempCheckdata.keys():\n",
    "                allCosdata[cos]['allIngredient'] = tempCheckdata[temp]\n",
    "    \n",
    "    toJson(result_path, allCosdata)\n",
    "    print(\"make Final productData Done!!\")\n",
    "\n",
    "def Naver_Month_Cosmetic(category):\n",
    "    destFolder = os.path.join(r'C:\\Final_Project_Files\\dataes\\Cosmetic\\tempData', category)\n",
    "    \n",
    "    MonthLi = []\n",
    "    for files in os.listdir(destFolder):\n",
    "        if files.endswith(\".txt\"):\n",
    "            data = openTxt(os.path.join(destFolder, files))\n",
    "            MonthLi += data\n",
    "            os.remove(os.path.join(destFolder, files))\n",
    "    \n",
    "    jsonName = datetime.today().strftime(\"%Y_%m_%d\") + f\"_Month_{category}.json\"\n",
    "    toJson(os.path.join(destFolder, jsonName), MonthLi)\n",
    "\n",
    "    return MonthLi\n",
    "\n",
    "def Final_Check_preprocessing(category):\n",
    "    FinalFolder = r'C:\\Final_Project_Files\\dataes\\Cosmetic\\Final'\n",
    "    IngreFolder = r'C:\\Final_Project_Files\\dataes\\Ingredient'\n",
    "    \n",
    "    FinalData = openJson(os.path.join(FinalFolder, f\"Final_{category}.json\"))\n",
    "    IngreDict = openJson(os.path.join(IngreFolder, 'Final_Ingredient_Dictionary.json'))\n",
    "    ingreName = [i['ingreName'] for i in IngreDict]\n",
    "    checkLi = []\n",
    "    \n",
    "    for product in FinalData:\n",
    "        for ingreDient in FinalData[product]['allIngredient']:\n",
    "            ingre = ingreDient.strip()\n",
    "            if ingre not in ingreName:\n",
    "                checkLi.append(ingre)\n",
    "    \n",
    "    resCheck = sorted(Counter(checkLi).items(), key=lambda x:x[1], reverse=True)\n",
    "    \n",
    "    for res in resCheck:\n",
    "        print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = r'C:\\Final_Project_Files\\Skin\\라운드랩 1025 독도 토너 200ml'\n",
    "\n",
    "productJson = openJson(os.path.join(test, 'product.json'))\n",
    "reviewJson = openJson(os.path.join(test, 'Reviews.json'))\n",
    "\n",
    "productName = list(productJson.keys())[0]\n",
    "productID = productJson[productName]['productID']\n",
    "\n",
    "preReviews = [sentence for sentence in sum([[re.sub(\"[^ 가-힣]+\", \"\", i).strip() for i in review.split(\"\\n\")] for review in reviewJson], []) if sentence != '']\n",
    "\n",
    "# [\" \".join([re.sub(\"[^ 가-힣]+\", \"\", i).strip() for i in review.split(\"\\n\")]) for review in reviewJson]\n",
    "preReviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalFolder = r'C:\\Final_Project_Files'\n",
    "FinalJsonFolder = r'C:\\Final_Project_Files\\dataes\\Cosmetic\\Final'\n",
    "categoryLi = [\"Skin\", \"Cream\", \"Lotion\"]\n",
    "checkLi = []\n",
    "\n",
    "FinalCheck = []\n",
    "for jsonfile in os.listdir(FinalJsonFolder):\n",
    "    if jsonfile.endswith(\".json\"):\n",
    "        jsonData = openJson(os.path.join(FinalJsonFolder, jsonfile))\n",
    "        for data in jsonData:\n",
    "            if jsonData[data]['allIngredient']:\n",
    "                FinalCheck.append(jsonData[data]['productID'])\n",
    "\n",
    "for cat in categoryLi:\n",
    "    categoryPath = os.path.join(FinalFolder, cat)\n",
    "    for files in os.listdir(categoryPath):\n",
    "        productsJson = openJson(os.path.join(categoryPath, files, 'product.json'))\n",
    "        reviewJson = openJson(os.path.join(categoryPath, files, 'Reviews.json'))\n",
    "        \n",
    "        productName = list(productsJson.keys())[0]\n",
    "        productID = productsJson[productName]['productID']\n",
    "        \n",
    "        if (productsJson[productName]['allIngredient']) or (productID in FinalCheck):\n",
    "            reviewDestFolder = os.path.join(FinalFolder, 'Reviews', productID)\n",
    "            if not os.path.exists(reviewDestFolder):\n",
    "                os.mkdir(reviewDestFolder)\n",
    "\n",
    "            preReviews = [sentence for sentence in sum([[re.sub(\"[^ 가-힣]+\", \"\", i).strip() for i in review.split(\"\\n\")] for review in reviewJson], []) if sentence != '']\n",
    "            \n",
    "            destData = {\"productID\" : productID, \"productName\" : productName, \"productReviews\" : preReviews}\n",
    "            \n",
    "            toJson(os.path.join(reviewDestFolder, 'preReviews.json'), destData)\n",
    "            # os.remove(os.path.join(categoryPath, files, 'Reviews.json'))\n",
    "            \n",
    "            checkLi.append([productName, productID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = r'C:\\Final_Project_Files\\dataes\\Cosmetic\\Final'\n",
    "\n",
    "cnt = 0\n",
    "dbcheck = []\n",
    "\n",
    "for i in os.listdir(pa):\n",
    "    catData = openJson(os.path.join(pa, i))\n",
    "    for data in catData:\n",
    "        if catData[data]['allIngredient']:\n",
    "            cnt += 1\n",
    "            dbcheck.append([data, catData[data]['productID']])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idsli = set([i[1] for i in checkLi])\n",
    "dbids = set([i[1] for i in dbcheck])\n",
    "\n",
    "wtf = dbids - idsli\n",
    "\n",
    "for i in dbcheck:\n",
    "    for w in wtf:\n",
    "        if i[1] == w:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "???\n"
     ]
    }
   ],
   "source": [
    "if {}:\n",
    "    print(\"!!\")\n",
    "else:\n",
    "    print(\"???\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d883de6d834198837d236f3f0eb6100f058ced473d573f54aa3c53db6094808"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
